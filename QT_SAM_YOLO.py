# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'untitled.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QApplication, QMainWindow
from PyQt5.QtCore import Qt, QEvent
from PyQt5.QtGui import QIcon, QPixmap, QImage
from PyQt5 import QtGui

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
#from models import net
import torch
from torch.autograd import Variable
import cv2
from PySide6.QtCore import QThread, Qt, Signal, Slot
import ultralytics
ultralytics.checks()
from ultralytics import YOLO
import torch
import matplotlib.pyplot as plt
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
import numpy as np
import cv2
import random



global Flag 
Flag = False

class Seg_Depth():
    def __init__(self):
        self.CMAP = np.load('cmap_nyud.npy')
        self.DEPTH_COEFF = 5000. # to convert into metres
        self.HAS_CUDA = torch.cuda.is_available()
        self.IMG_SCALE  = 1./255
        self.IMG_MEAN = np.array([0.485, 0.456, 0.406]).reshape((1, 1, 3))
        self.IMG_STD = np.array([0.229, 0.224, 0.225]).reshape((1, 1, 3))
        self.MAX_DEPTH = 8.
        self.MIN_DEPTH = 0.
        self.NUM_CLASSES = 40
        self.NUM_TASKS = 2 # segm + depth
        self.model = net(num_classes=self.NUM_CLASSES, num_tasks=self.NUM_TASKS)


        if self.HAS_CUDA:
            _ = self.model.cuda()
        _ = self.model.eval()

        ckpt = torch.load('weights//ExpNYUD_joint.ckpt')
        self.model.load_state_dict(ckpt['state_dict'])
    
    def prepare_img(self, img):
        return (img * self.IMG_SCALE - self.IMG_MEAN) / self.IMG_STD
    
    def __call__(self, img_nyud):
        with torch.no_grad():
            # nyud
            img_var = Variable(torch.from_numpy(self.prepare_img(img_nyud).transpose(2, 0, 1)[None]), requires_grad=False).float()
            if self.HAS_CUDA:
                img_var = img_var.cuda()
            segm, depth = self.model(img_var)
            segm = cv2.resize(segm[0, :(self.NUM_CLASSES)].cpu().data.numpy().transpose(1, 2, 0),
                            img_nyud.shape[:2][::-1],
                            interpolation=cv2.INTER_CUBIC)
            depth = cv2.resize(depth[0, 0].cpu().data.numpy(),
                            img_nyud.shape[:2][::-1],
                            interpolation=cv2.INTER_CUBIC)
            segm_nyud = self.CMAP[segm.argmax(axis=2) + 1].astype(np.uint8)
            depth_nyud = np.abs(depth)
        return segm_nyud, depth_nyud

    


class Stadium(QtWidgets.QLabel):
    def __init__(self, pixmap):
        super().__init__()
        self.setMouseTracking(True)
        self.pixmap = pixmap

    def mouseMoveEvent(self, event):
        self.pos = event.pos()
        print(f"Mouse moved to ({x}, {y})")
        self.update()



class Thread(QThread):

    def __init__(self, qphoto , qseg ):
        super().__init__()
        self.qphoto = qphoto
        self.qseg = qseg
       # self.model = Seg_Depth()
        self.depth = ""
        self.frame = ""
        self.model = YOLO('SAM_YOLO8//yolov8n.pt')
        self.DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.sam = sam_model_registry["vit_b"](checkpoint="Segment_anything//sam_vit_b_01ec64.pth").to(device=self.DEVICE)
        self.mask_predictor = SamPredictor(self.sam)
    

    def show_mask(self, mask, image,random_color=True ):
        if random_color:
            color = random.sample(range(1, 255), 3)
        else:
            color = np.array([30/255, 144/255, 255/255, 0.6])
        #color = color.reshape(1, 1, 3)
        h, w = mask.shape[-2:]
        mask.dtype = np.uint8()
        mask = mask.reshape(h, w, 1)
        
        image[(mask==1).all(-1)] = color
        return image
    
   
    def show_points(self, coords, labels, ax, marker_size=375):
        pos_points = coords[labels==1]
        neg_points = coords[labels==0]
        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)
        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   
    
    def show_box(self, box , name , image):
        x0, y0 = box[0], box[1]
        w, h = box[2] - box[0], box[3] - box[1]
        image = cv2.rectangle(image , (int(x0)+5, int(y0)+5), (int(x0+w), int(y0+h)), [0,0,255] ,  2)  
        font = cv2.FONT_HERSHEY_SIMPLEX
        image = cv2.putText(image ,name, (int(x0)+5,int(y0)+25) , font , 1 , [0,0,0] , 2 ,  cv2.LINE_AA)
        return image

    def run(self):
        video_capture = cv2.VideoCapture("IMG_2860.MOV")
    
        while (video_capture.isOpened() and Flag == False):
            
            ret, frame = video_capture.read()

            if not ret:
                break

            # Perform inference on frame
            frame = cv2.resize(frame, (640, 480), 
               interpolation = cv2.INTER_LINEAR)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            Org = np.copy(frame)
            image = np.array(frame)
            h, w, ch = image.shape
            #img_nyud = np.array(Image.open(img_path))
            results= self.model(frame , conf=0.25)[0]
            bbox = results.boxes.xyxy.tolist()
            names = []
            for i in results.boxes.cls.cpu().detach().numpy().tolist():
                names.append(results.names[i])


            self.mask_predictor.set_image(frame)
            counter = 0 
            for boz in bbox:
                input_box = np.array(boz)
                masks, _, _ = self.mask_predictor.predict(
                    point_coords=None,
                    point_labels=None,
                    box=input_box[None,:],
                    multimask_output=False,
                )

                
                frame = self.show_mask(masks[0] , frame )
                frame = self.show_box(input_box  , names[counter] , frame)
                counter+=1


            bytesPerLine = ch * w
            pix_seg = QImage(Org, w, h, bytesPerLine, QImage.Format_RGB888)
            pix_Org = QImage(frame, w, h, bytesPerLine, QImage.Format_RGB888)


            self.qphoto.setPixmap(QPixmap.fromImage(pix_seg)) 
            self.qseg.setPixmap(QPixmap.fromImage(pix_Org)) 
            self.depth = ""
            self.frame = frame
    
    def stop(self):
        self.isRunning=False
        self.quit()
        self.terminate()

        return self.depth









class mywindow(QMainWindow):
    def __init__(self , address=""):
        super().__init__()
        self.setMouseTracking(True)
        self.setObjectName("MainWindow")
        self.resize(1224, 898)
        self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        self.setMouseTracking(False)
        self.centralwidget = QtWidgets.QWidget(self)
        self.centralwidget.setObjectName("centralwidget")
        self.Photo_Org = QtWidgets.QLabel(self.centralwidget)
        self.Photo_Org.setGeometry(QtCore.QRect(0, 0, 640, 480))
        self.Photo_Org.setObjectName("Photo_Org")
        self.Photo_Sem = QtWidgets.QLabel(self.centralwidget)
        self.Photo_Sem.setGeometry(QtCore.QRect(650, 0, 640, 480))
        self.Photo_Sem.setObjectName("Photo_Sem")
        self.B1 = QtWidgets.QPushButton(self.centralwidget)
        self.B1.setGeometry(QtCore.QRect(430, 690, 93, 28))
        self.B1.setObjectName("B1")
        self.textEdit = QtWidgets.QTextEdit(self.centralwidget)
        self.textEdit.setGeometry(QtCore.QRect(773, 640, 231, 141))
        self.textEdit.setObjectName("textEdit")
        self.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(self)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 1224, 26))
        self.menubar.setObjectName("menubar")
        self.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(self)
        self.statusbar.setObjectName("statusbar")
        self.setStatusBar(self.statusbar)


        self.B2 = QtWidgets.QPushButton(self.centralwidget)
        self.B2.setGeometry(QtCore.QRect(530, 690, 93, 28))
        self.B2.setObjectName("B2")
        self.B2.setText("Stop")
        self.B2.clicked.connect(self.Click_B2)
        #self.Photo_Org = Stadium('D:\\Projects\\SANAYE\\MODEL\\Capture.PNG')
        #self.Photo_Org.setPixmap(QtGui.QPixmap('D:\\Projects\\SANAYE\\MODEL\\Capture.PNG'))
        self.Photo_Org.setPixmap(QtGui.QPixmap("Capture.png"))

        self.retranslateUi(self)
        QtCore.QMetaObject.connectSlotsByName(self)

        self.installEventFilter(self)
        self.B1.clicked.connect(self.click)

        self.address = address
        self.depth = "" 
        self.th = Thread(self.Photo_Org , self.Photo_Sem)


    def Click_B2(self):
        self.depth = self.th.stop()


    def click(self):
        # self.Photo_Org.setPixmap(QtGui.QPixmap("Capture.png"))
        # self.Photo_Org.setScaledContents(True)
        
        self.th.start()
        # if self.address != "":
        #     video_capture = cv2.VideoCapture(self.address)
        # else:
        #     video_capture = cv2.VideoCapture(0)
            
        # if not video_capture.isOpened():
        #     print("Error: Could not open video file.")
        #     exit()

        # while (video_capture.isOpened()):
            
        #     ret, frame = video_capture.read()

        #     if not ret:
        #         break

        #     # Perform inference on frame
        #     frame = cv2.resize(frame, (640, 480), 
        #        interpolation = cv2.INTER_LINEAR)
        #     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        #     image = np.array(frame)
        #     h, w, ch = image.shape
        #     #img_nyud = np.array(Image.open(img_path))
        #     seg , depth = self.model(frame)
        #     bytesPerLine = ch * w
        #     pix_seg = QImage(frame, w, h, bytesPerLine, QImage.Format_RGB888)
        #     pix_Org = QImage(seg, w, h, bytesPerLine, QImage.Format_RGB888)

        #     #self.Photo_Org.setPixmap(pix_Org)
        #     #self.Photo_Sem.setPixmap(pix_seg)
        #     self.Photo_Org.setPixmap(QPixmap.fromImage(pix_seg))
        #     self.Photo_Sem.setPixmap(QPixmap.fromImage(pix_Org))
        #     self.Photo_Org.update()
        #     self.Photo_Sem.update()
            





    def eventFilter(self, obj, event):
        if event.type() == QEvent.MouseMove:
            x = event.x()
            y = event.y()
            #self.textEdit.setText(f"Mouse moved to ({x}, {y})")
            if( (x in range(640)) and (y in range(480)) ):
                self.textEdit.setText(f"the depth for ({x}, {y}) is {self.depth[y,x]}")
            else:
                self.textEdit.setText("out of range")

        return super().eventFilter(obj, event)

    



    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "Test_Drive"))
        self.Photo_Org.setText(_translate("MainWindow", "TextLabel"))
        self.Photo_Sem.setText(_translate("MainWindow", "TextLabel"))
        self.B1.setText(_translate("MainWindow", "Start"))



if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    window = mywindow(address="IMG_2860.MOV")
    
    window.show()
    sys.exit(app.exec_())
